{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = set()\n",
    "\n",
    "with open('./../ruznezecy/polish_corpora.txt', 'r', encoding='utf8') as corpora:\n",
    "    for line in corpora:\n",
    "        for token in line.split():\n",
    "            data.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['piekarnik', 'grzeje', 'kuchnię']\n",
      "['król', 'karol', 'kupił', 'królowej', 'karolinie', 'korale', 'koloru', 'koralowego']\n",
      "['kotek', 'lekt', 'ycz', 'niewy', 'łania', 'sięz', 'kurnika']\n"
     ]
    }
   ],
   "source": [
    "def max_match(untokenized_word):\n",
    "    result_tokens = []\n",
    "    start_letter = 0\n",
    "    while start_letter < len(untokenized_word):\n",
    "        maxi = \"\"\n",
    "        for end_letter in range(start_letter, len(untokenized_word)):\n",
    "            current = untokenized_word[start_letter : end_letter + 1]\n",
    "            if current in data and len(current) > len(maxi):\n",
    "                maxi = current\n",
    "        start_letter = start_letter + len(maxi)\n",
    "        result_tokens.append(maxi)\n",
    "    print(result_tokens)\n",
    "max_match(\"piekarnikgrzejekuchnię\")\n",
    "max_match(\"królkarolkupiłkrólowejkaroliniekoralekolorukoralowego\")\n",
    "max_match(\"koteklektyczniewyłaniasięzkurnika\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_tokenize = []\n",
    "number_of_lines = 0\n",
    "with open('./../ruznezecy/polish_corpora.txt', 'r', encoding='utf8') as corpora:\n",
    "    for line in corpora:\n",
    "        if number_of_lines < 12000:\n",
    "            for token in line.split():\n",
    "                string_to_tokenize.append(token)\n",
    "            number_of_lines += 1\n",
    "        else:\n",
    "            break\n",
    "string_to_tokenize = [token.lower() for token in string_to_tokenize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['System', 'Euroraty', 'Chcesz', 'kupować', 'więcej', 'niż', 'gdzie', 'indziej', '?', 'Parlament', 'zdecydował', 'jednak', 'inaczej', 'i', 'przyjął', 'w', 'ustawie', 'z', 'dnia', '28.06.1996', 'r.', 'jednoinstancyjne', 'postępowanie', 'orzeczniczo-lekarskie', '.', 'Po', 'kampanii', 'wrześniowej', '1.DLek', 'raportowała', '77', 'czołgów', 'L.T.M.35', 'utraconych', '(', 'wraz', 'z', 'wozami', 'dowodzenia', ')', 'i', '52', 'uszkodzone', 'lub', 'zepsute', ',', 'lecz', 'ostatecznie', 'po', 'naprawach', 'straty', 'bezpowrotne', 'ograniczyły', 'się', 'do', '7', 'czołgów', 'i', 'w', 'lutym', '1940', 'roku', 'posiadano', '195', 'czołgów', 'na', 'stanie', '.', 'W', 'rolach', 'głównych', 'wystąpili', 'Jake', 'Gyllenhaal', ',', 'Forest', 'Whitaker', 'oraz', 'Rachel', 'McAdams', '.', 'Zapieczone', 'z', 'pomidorami', ',', 'bazylią', 'i', 'serem', '...', 'Może', 'ten', 'przypadek', 'odstraszy', 'innych', 'kłusowników', 'od', 'tego', 'procederu', '.', 'Ulgi', 'i', 'przywileje', 'są', 'w', 'stosunkach', 'między', 'państwami', 'zwykle', 'wzajemne', ',', 'ambasador', 'ma', 'tu', 'niewielkie', 'pole', 'działania', '.', 'Pośród', 'wzgórz', 'do', 'strony', 'południowej', 'do', 'państwa', 'wpływał', 'Wierzbiak', ',', 'który', 'znany', 'był', 'już', 'ze', 'złotonośnych', 'piasków', '.', 'Tutaj', 'możecie', 'zobaczyć', ',', 'jak']\n"
     ]
    }
   ],
   "source": [
    "print(string_to_tokenize[0:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
